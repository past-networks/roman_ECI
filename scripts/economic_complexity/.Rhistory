"Greek peninsula",
"Anatolia",
"Greater Syria",
"Egypt",
"North Africa"),
tot_pop_min = c(12000000,
7000000,
9000000,
1500000,
5000000,
2500000,
9000000,
5000000,
5000000,
7000000),
tot_pop_max = c(13000000,
9000000,
12000000,
2000000,
6000000,
3000000,
10000000,
6000000,
6000000,
8000000))
# Data based on "Scheidel W. Demography. In: Scheidel W, Morris I, Saller RP, eds. The Cambridge Economic History of the Greco-Roman World. Cambridge University Press; 2007:38-86." Table 3.1
macroregion_pop_165AD_df <- data.frame(
macroregion = c("Italy and islands",
"Iberia",
"Gaul and Germany",
"Britain",
"Danubian region",
"Greek peninsula",
"Anatolia",
"Greater Syria",
"Egypt",
"North Africa"),
tot_pop_min = c(12000000,
7000000,
9000000,
1500000,
5000000,
2500000,
9000000,
5000000,
5000000,
7000000),
tot_pop_max = c(13000000,
9000000,
12000000,
2000000,
6000000,
3000000,
10000000,
6000000,
6000000,
8000000))
# total and urban population
macroregion_pop_165AD_rural_urban_df <- left_join(
macroregion_pop_165AD_df,
macroregions_urban_population_df)
# rural population
macroregion_pop_165AD_rural_urban_df$rural_pop_min <- macroregion_pop_165AD_rural_urban_df$tot_pop_min - macroregion_pop_165AD_rural_urban_df$urban_pop
macroregion_pop_165AD_rural_urban_df$rural_pop_max <-
macroregion_pop_165AD_rural_urban_df$tot_pop_max - macroregion_pop_165AD_rural_urban_df$urban_pop
# add the province's urban population to the full info df
provinces_macroregions_full_info_df <- left_join(
provinces_macroregions_full_info_df,
province_urban_population_df
)
# add the populations of the macroregion
provinces_macroregions_full_info_df <- left_join(
provinces_macroregions_full_info_df,
# add prefix macroregion to the column names to avoid confusion
macroregion_pop_165AD_rural_urban_df %>%
setNames(c("macroregion",
paste0(
"macroregion_",
colnames(macroregion_pop_165AD_rural_urban_df)[-1])))
)
# add the rural population proportionately to the area of the province
provinces_macroregions_full_info_df$rural_pop_max <-
provinces_macroregions_full_info_df$macroregion_rural_pop_max*provinces_macroregions_full_info_df$area_proportion
provinces_macroregions_full_info_df$rural_pop_min <-
provinces_macroregions_full_info_df$macroregion_rural_pop_min*provinces_macroregions_full_info_df$area_proportion
# compute the min/max total population for each province
provinces_macroregions_full_info_df$tot_pop_min <- provinces_macroregions_full_info_df$urban_pop+
provinces_macroregions_full_info_df$rural_pop_min
provinces_macroregions_full_info_df$tot_pop_max <- provinces_macroregions_full_info_df$urban_pop+
provinces_macroregions_full_info_df$rural_pop_max
# compare these two data frames with the population in macroregion_pop_165AD_df
provinces_macroregions_full_info_df %>% group_by(macroregion) %>%
summarize(pop = sum(tot_pop_min))
provinces_macroregions_full_info_df %>% group_by(macroregion) %>%
summarize(pop = sum(tot_pop_max))
provinces_population_df <-
provinces_macroregions_full_info_df[,c("province",
"urban_pop",
"rural_pop_min",
"rural_pop_max",
"tot_pop_min",
"tot_pop_max")]
# set row names
rownames(provinces_population_df) <- provinces_population_df$province
provinces_rural_pc_df <- data.frame(
province = provinces_population_df$province,
"min" = provinces_population_df$rural_pop_min/provinces_population_df$tot_pop_min,
"max" = provinces_population_df$rural_pop_max/provinces_population_df$tot_pop_max
)
# add area info to countries
world_sf$area <- st_area(world_sf)
# find intersections between the two shapefiles of modern day countries and provinces
intersections <- st_intersection(world_sf,provinces) %>%
dplyr::select(c("iso3","area","province","geometry")) %>% # select only needed columns
setNames(c("country","country_area","province","geometry"))
# calculate the area of each intersection
intersections$intersection_area <- st_area(intersections)
# save info in a dataframe for easier retrival
intersections_df <- st_drop_geometry(intersections)
# add ID columns
intersections_df$intersection_ID <- paste(
seq_len(nrow(intersections_df)),
intersections_df$country,
intersections_df$province ) %>%
str_replace_all(" ","_")
# place ID column as first one
intersections_df <- intersections_df[,c("intersection_ID","country","province","country_area","intersection_area")]
# compute the sum of the areas of the intersections
check_areas_intersections_df <- intersections_df %>%
group_by(province) %>%
summarize(sum_intersection_areas = sum (intersection_area)) %>%
left_join(provinces_areas_df)
# compare the sum of the areas of the intersections with the area of the province
check_areas_intersections_df$area_correction_factor <- check_areas_intersections_df$sum_intersection_areas/check_areas_intersections_df$area
# add sum of the areas of the intersections to the df of intersections
intersections_df <- left_join(
intersections_df,
check_areas_intersections_df[c("province","sum_intersection_areas")]
)
# compute the proportion by dividing the areas
intersections_df$prop_intersection_area <- intersections_df$intersection_area/intersections_df$sum_intersection_areas
# merge info on intersections and rural population of the provinces
intersections_pop_full_info_df <- left_join(
intersections_df[c("intersection_ID","country","province","prop_intersection_area")],
provinces_population_df[c("province","rural_pop_min","rural_pop_max")]) %>% setNames(c("intersection_ID","country","province","prop_intersection_area","province_rural_pop_min","province_rural_pop_max"))
# compute estimates of rural population of intersections
intersections_pop_full_info_df$intersection_rural_pop_min <- as.numeric(intersections_pop_full_info_df$province_rural_pop_min*intersections_pop_full_info_df$prop_intersection_area)
intersections_pop_full_info_df$intersection_rural_pop_max <- as.numeric(intersections_pop_full_info_df$province_rural_pop_max*intersections_pop_full_info_df$prop_intersection_area)
# assign each city to its closest intersection
closest_intersection_to_city_index <- st_nearest_feature(cities,intersections)
cities_in_intersections_df <- data.frame(
Primary.Key = cities$Primary.Key,
Ancient.Toponym = cities$Ancient.Toponym,
pop_est = cities$pop_est,
intersection_ID = intersections_df$intersection_ID[closest_intersection_to_city_index]
)
# compute the urban population by intersection
intersections_urban_population_df <- cities_in_intersections_df %>%
group_by(intersection_ID) %>%
summarize(intersection_urban_pop = sum(pop_est))
# add a row with value 0
intersections_urban_population_df <- rbind(
intersections_urban_population_df,
data.frame(
intersection_ID = intersections_df$intersection_ID[
which(!intersections_df$intersection_ID %in%
intersections_urban_population_df$intersection_ID)],
intersection_urban_pop = 0
)
)
# sort alphabetically
intersections_urban_population_df <- intersections_urban_population_df[order(intersections_urban_population_df$intersection_ID),]
# urban population
intersections_pop_full_info_df <- left_join(intersections_pop_full_info_df,
intersections_urban_population_df)
# total population
intersections_pop_full_info_df$intersection_tot_pop_min <-
intersections_pop_full_info_df$intersection_rural_pop_min +
intersections_pop_full_info_df$intersection_urban_pop
intersections_pop_full_info_df$intersection_tot_pop_max <-
intersections_pop_full_info_df$intersection_rural_pop_max +
intersections_pop_full_info_df$intersection_urban_pop
intersections_pop_full_info_df %>%
group_by(province) %>%
summarize(preliminary_sum_min=sum(intersection_tot_pop_max))  %>%
left_join(
provinces_macroregions_full_info_df[c("province","tot_pop_max","tot_pop_min")]
)
# compute the population
countries_population_df <-  intersections_pop_full_info_df %>%
group_by(country) %>%
summarize(urban_pop= sum(intersection_urban_pop),
rural_pop_min = sum(intersection_rural_pop_min),
rural_pop_max = sum(intersection_rural_pop_max),
tot_pop_min = sum(intersection_tot_pop_min),
tot_pop_max = sum(intersection_tot_pop_max)) %>%
as.data.frame() %>%
na.omit()
rownames(countries_population_df) <- countries_population_df$country
# check validity of grand total
(sum(provinces_macroregions_full_info_df$tot_pop_min) == sum(countries_population_df$tot_pop_min) && sum(provinces_macroregions_full_info_df$tot_pop_max) == sum(countries_population_df$tot_pop_max))
# save results
#write.csv(countries_population_df,
#          "../../results/economic_complexity/countries_population.csv")
#write.csv(intersections_pop_full_info_df,
#          "../../results/economic_complexity/intersections_population_full_info.csv")
countries_rural_pc_df <- data.frame(
country = countries_population_df$country,
"min" = countries_population_df$rural_pop_min/countries_population_df$tot_pop_min,
"max" = countries_population_df$rural_pop_max/countries_population_df$tot_pop_max
) %>% na.omit()
# read csv with info on when provinces were conquered/lost
province_dates_df <- read.csv("../../data/economic_complexity/province_dates.csv",sep=";")
# order alphabetically
provinces_population_df <- provinces_population_df[order(provinces_population_df$province),]
province_dates_df <- province_dates_df[order(province_dates_df$province),]
# build data.frame of population multipliers
n_iter <- 1000
years <- c(min(province_dates_df$start_date):-1,1:max(province_dates_df$end_date))
n_years <- abs(min(province_dates_df$start_date)) + max(province_dates_df$end_date)
# extract the growth rates from a triangular distribution
growth_rate_samples <- rtri(n_iter,min=0,max=0.005,mode=0.0015)
# define the population functions
integrand_to_165AD <- function(x){(1-r)^(165-x)}
integrand_from_165AD <- function(x){(1-r)^(x-165)}
# initialise population results
provinces_total_population_df <- data.frame(
iter = rep(seq_len(n_iter), each = nrow(provinces_population_df)),
province = rep(provinces_population_df$province,n_iter),
urb_pop_grand_total = 0,
rural_pop_min_grand_total = 0,
rural_pop_max_grand_total = 0,
tot_pop_min_grand_total = 0,
tot_pop_max_grand_total = 0)
for (i in seq_len(n_iter)) {
r <- growth_rate_samples[i]
for (j in seq_len(nrow(province_dates_df))){
# find the start and end date of each province (THIS SHOULD BE DONE WITH VECTORS IN THE FUTURE)
start_date <- province_dates_df$start_date[j]
end_date <- province_dates_df$end_date[j]
# find integral
integral_to_165AD <- integrate(integrand_to_165AD,start_date,min(end_date,165))
integral_from_165AD <- integrate(integrand_to_165AD,max(start_date,165),end_date)
integral_total <- integral_to_165AD$value + integral_from_165AD$value
# add values to df
provinces_total_population_df[(i-1)*nrow(provinces_population_df)+j,
c("urb_pop_grand_total",
"rural_pop_min_grand_total",
"rural_pop_max_grand_total",
"tot_pop_min_grand_total",
"tot_pop_max_grand_total")] <-
integral_total*provinces_population_df[j,c("urban_pop","rural_pop_min","rural_pop_max","tot_pop_min","tot_pop_max")]
}
print(i)
}
# save results
#write.csv(provinces_total_population_df,"../../results/economic_complexity/provinces_total_population.csv")
# province
# count epitaphs by province
epitaphs_in_provinces_counts <- epitaphs_in_provinces$province %>%
table() %>%
as.data.frame() %>%
setNames(c("province","epitaphs"))
# province
# count epitaphs by province
epitaphs_in_provinces_counts <- epitaphs_in_provinces$province %>%
table() %>%
as.data.frame() %>%
setNames(c("province","epitaphs"))
knitr::opts_chunk$set(echo = TRUE)
required_packages <- c("jsonlite",     # read json files
"arrow",        # read parquet files
"tidyverse",    # data cleaning and visualisation
"stringi",      # handle strings for spelling standardisation
"sf",           # load and handle spatial files
"raster",       # handle spatial files
"units",        # add physical units for geographic comparison
"ggspatial",    # additional plot features for spatial data
"triangulr",    # triangular distribution
"Matrix")       # for eigenvalues
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up
inscriptions <- read_parquet("../../data/large_data/LIST_occups.parquet") # new data after Petra's cleanup
knitr::opts_chunk$set(echo = TRUE)
required_packages <- c("jsonlite",     # read json files
"arrow",        # read parquet files
"tidyverse",    # data cleaning and visualisation
"stringi",      # handle strings for spelling standardisation
"sf",           # load and handle spatial files
"raster",       # handle spatial files
"units",        # add physical units for geographic comparison
"ggspatial",    # additional plot features for spatial data
"triangulr",    # triangular distribution
"Matrix")       # for eigenvalues
packages_to_install <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(packages_to_install)) install.packages(packages_to_install)
invisible(lapply(required_packages, library, character.only = TRUE))
# R version
R.version
# example package version
packageVersion("tidyverse")
# #install devtools if not already installed
# if (!"devtools" %in% installed.packages()[,"Package"]) install.packages("devtools")
#
# #load devtools
# library(devtools)
#
# #install specific versions of the packages
# install_version("jsonlite", version = "1.8.7")
# install_version("arrow", version = "15.0.1")
# install_version("tidyverse", version = "2.0.0")
# install_version("stringi", version = "1.7.12")
# install_version("sf", version = "1.0.15")
# install_version("raster", version = "3.6.26")
# install_version("units", version = "0.8.2")
# install_version("ggspatial", version = "1.1.9")
# install_version("triangulr", version = "1.2.1")
# install_version("Matrix", version = "1.6.1")
#
# #load packages
# invisible(lapply(required_packages, library, character.only = TRUE))
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up
inscriptions <- read_parquet("../../data/large_data/LIST_occups.parquet") # new data after Petra's cleanup
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up
inscriptions <- read_parquet("../../data/large_data/LIST_occups_simple.parquet") # new data after Petra's cleanup
# occupations to merge
occupations_all <- read_delim("../../data/economic_complexity/occupations.csv", delim=";")
occupations_to_merge <- read_delim("../../data/economic_complexity/occupations_to_merge.csv", delim=";")
# inscriptions containing people
EDH_people <- read_csv("../../data/economic_complexity/EDH_people_2021.csv")
# epitaphs
epitaphs <- inscriptions[inscriptions$type_of_inscription_auto %in% c("epitaph"),]
# greek inscriptions
greek_inscriptions <- read_parquet("../../data/large_data/GIST_v1-1.parquet") # manually downloaded from zenodo.org/records/10127597
View(inscriptions)
# inscriptions
inscriptions1 <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up
View(inscriptions1)
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up, 511973 inscriptions
inscriptions <- read_parquet("../../data/large_data/LIST_occups_simple.parquet") # new data after Petra's cleanup, 525870 inscriptions
# occupations to merge
occupations_all <- read_delim("../../data/economic_complexity/occupations.csv", delim=";")
occupations_to_merge <- read_delim("../../data/economic_complexity/occupations_to_merge.csv", delim=";")
# inscriptions containing people
EDH_people <- read_csv("../../data/economic_complexity/EDH_people_2021.csv")
# epitaphs
epitaphs <- inscriptions[inscriptions$type_of_inscription_auto %in% c("epitaph"),]
# greek inscriptions
greek_inscriptions <- read_parquet("../../data/large_data/GIST_v1-1.parquet") # manually downloaded from zenodo.org/records/10127597
names(inscriptions)
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up, 511973 inscriptions
inscriptions <- read_parquet("../../data/large_data/LIST_occups_simple.parquet") # new data after Petra's cleanup, 525870 inscriptions
# occupations to merge
occupations_all <- read_delim("../../data/economic_complexity/occupations.csv", delim=";")
occupations_to_merge <- read_delim("../../data/economic_complexity/occupations_to_merge.csv", delim=";")
# inscriptions containing people
EDH_people <- read_csv("../../data/economic_complexity/EDH_people_2021.csv")
# epitaphs
epitaphs <- inscriptions[inscriptions$type_of_inscription_auto %in% c("epitaph"),]
# greek inscriptions
greek_inscriptions <- read_parquet("../../data/large_data/GIST_v1-1.parquet") # manually downloaded from zenodo.org/records/10127597
knitr::opts_chunk$set(echo = TRUE)
required_packages <- c("jsonlite",     # read json files
"arrow",        # read parquet files
"tidyverse",    # data cleaning and visualisation
"stringi",      # handle strings for spelling standardisation
"sf",           # load and handle spatial files
"raster",       # handle spatial files
"units",        # add physical units for geographic comparison
"ggspatial",    # additional plot features for spatial data
"triangulr",    # triangular distribution
"Matrix")       # for eigenvalues
packages_to_install <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(packages_to_install)) install.packages(packages_to_install)
invisible(lapply(required_packages, library, character.only = TRUE))
# R version
R.version
# example package version
packageVersion("tidyverse")
# #install devtools if not already installed
# if (!"devtools" %in% installed.packages()[,"Package"]) install.packages("devtools")
#
# #load devtools
# library(devtools)
#
# #install specific versions of the packages
# install_version("jsonlite", version = "1.8.7")
# install_version("arrow", version = "15.0.1")
# install_version("tidyverse", version = "2.0.0")
# install_version("stringi", version = "1.7.12")
# install_version("sf", version = "1.0.15")
# install_version("raster", version = "3.6.26")
# install_version("units", version = "0.8.2")
# install_version("ggspatial", version = "1.1.9")
# install_version("triangulr", version = "1.2.1")
# install_version("Matrix", version = "1.6.1")
#
# #load packages
# invisible(lapply(required_packages, library, character.only = TRUE))
# inscriptions
#inscriptions <- read_parquet("../../data/economic_complexity/LIST_occupsorgs_industry_simple_20231206.parquet") # this is the old data from before Petra's clean up, 511973 inscriptions
inscriptions <- read_parquet("../../data/large_data/LIST_occups_simple.parquet") # new data after Petra's cleanup, 525870 inscriptions
# occupations to merge
occupations_all <- read_delim("../../data/economic_complexity/occupations.csv", delim=";")
occupations_to_merge <- read_delim("../../data/economic_complexity/occupations_to_merge.csv", delim=";")
# inscriptions containing people
EDH_people <- read_csv("../../data/economic_complexity/EDH_people_2021.csv")
# epitaphs
epitaphs <- inscriptions[inscriptions$type_of_inscription_auto %in% c("epitaph"),]
# greek inscriptions
greek_inscriptions <- read_parquet("../../data/large_data/GIST_v1-1.parquet") # manually downloaded from zenodo.org/records/10127597
# cities based on Hanson's dataset
cities <- st_read("../../data/economic_complexity/roman_cities_pop.geojson")
# Roman provinces (digitised and corrected by Adam PaÅ¾out)
provinces <- read_sf("../../data/economic_complexity/provinces/provinces.shp")
# country borders
## Orginal data can be download from https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/world-administrative-boundaries/exports/shp
world_sf <- read_sf('../../data/economic_complexity/world-administrative-boundaries/world-administrative-boundaries.shp')
## dissolve the administrative boundaries for visualisation purposes
world_no_borders_sf <- st_union(world_sf)
plot_and_save <-  function(ggp, title=deparse(substitute(ggp)), width = 7, height = 5.5){
# print the plot
#print(ggp)
# save the plot (deafault title is the name of the file)
ggsave(paste0("../../figures/economic_complexity/",title,".pdf"),
ggp, width = width, height = height)
#ggsave(paste0("../../figures/economic_complexity/",title,".jpeg"),
#       ggp, width = width, height = height, dpi = 300)
}
which_gu <- function(d){
if (is.data.frame(d)){
# ensure that the info on geographical unit (gu) is included in the input
if ("province" %in% colnames(d)){
gu <- "province"
} else if ("country" %in% colnames(d)){
gu <- "country"
} else {
stop("The input dataframe does not contain info on the geographical unit")
}
} else if (is.table(d)){
# check that the table contains a couple of names of provinces or countries (to avoid problem with future bootstrapping)
if (any(c("Achaia", "Aegyptus") %in%  rownames(d))){
gu <- "province"
} else if (any(c("ITA", "FRA") %in%  rownames(d))){
gu <- "country"
} else {
stop("The input table does not contain info on the geographical unit")
}
} else {
stop("The input is neither a table nor a dataframe")
}
return(gu)
}
sort_table <- function(tb, decreasing = TRUE){
# col names sorted by sums
col_names <- names(
sort(
colSums(tb),
decreasing=decreasing)
)
# row names (sorted by sums)
row_names <- names(
sort(
rowSums(tb),
decreasing=decreasing)
)
# apply sorting
tb <- tb[row_names,col_names]
return(tb)
}
inscriptions_w_occupations <- inscriptions[inscriptions$occups_N>0,]
occupations_to_merge_min <- occupations_to_merge[,c("Main_term","To_be_merged")]
occupations_to_merge_separated <- occupations_to_merge_min %>%
separate_rows(To_be_merged, sep = ", ") %>%
mutate(To_be_merged = trimws(To_be_merged)) # Remove leading/trailing spaces if any
# Rename columns if needed
colnames(occupations_to_merge_separated) <- c("standard_spelling", "alternative_spellings")
# ensure no unwanted space are there in the terms
occupations_all$Term <- trim(occupations_all$Term)
# find full names of occupations by attaching Term2 if present
occupations_all$Term_full <- ifelse(!is.na(occupations_all$Term2),
paste(occupations_all$Term,occupations_all$Term2),
occupations_all$Term)
#initialise column of standard spelling
occupations_all$std_spelling <- NA
for (i in seq(nrow(occupations_all))) {
occ_term <- occupations_all$Term_full[i]
# CHECK THIS
occupations_all$std_spelling[i] <- ifelse(occ_term %in% occupations_to_merge_separated$alternative_spellings,
occupations_to_merge_separated$standard_spelling[which(occupations_to_merge_separated$alternative_spellings==occ_term)],
occ_term
)
}
# select only necessary columns
occupations_dictionary <- unique(occupations_all[,c("Term_full","std_spelling")]) %>%
setNames(c("Term","std_spelling"))
# initialise new column of standard spelling for occupations in inscriptions
inscriptions_w_occupations$occups_std <- rep(list(NA),nrow(inscriptions_w_occupations))
for (i in seq(nrow(inscriptions_w_occupations))){
# extract an inscription
inscription <- inscriptions_w_occupations[i,]
# find the occupations in the inscription and associate it with the standard spellings
inscription_occ <- data.frame(Term=unlist(inscription$occups)) %>%
left_join(occupations_dictionary,
by = "Term")
# save the standard spellings for the occupations in the inscription
inscriptions_w_occupations$occups_std[[i]] <- inscription_occ$std_spelling
}
